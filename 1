1.If 7TB is the available disk space per node (9 disks with 1 TB, 2 disk for operating system etc. were excluded.).
Assuming initial data size is 600 TB. How will you estimate the number of data nodes (n)?
       Formula to calaculate no of data nodes: n=(H/d)=((c*r*S)/(1-i))/d;
       where,d=diskspace available per node-7TB;
             c-compression ratio depends on the type of compression used ,when no compression it is 1,let us consider as 1,
             r-replication factor,let us consider the default 3;
             S-initial size of data has to be moved to hadoop;
             i-intermediate data factor.it may be 1/4 or 1/3;
             H=(1*3*600)/(1-1/4)=2400TB;
             n=H/d=2400/7=342.85(approx 345 data nodes)
2.Imagine that you are uploading a file of 500MB into HDFS.100MB of data is successfully uploaded into HDFS and 
another client wants to read the uploaded data while the upload is still in progress. What will happen in such a
scenario, will the 100 MB of data that is uploaded will it be displayed?
          

             
